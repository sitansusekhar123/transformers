{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from data_loader import DatasetLanguage, collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import Transformer\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = '../data/train.json'\n",
    "testing_path = '../data/test.json'\n",
    "validation_path = '../data/validation.json'\n",
    "x_vocab = '../data/english_map.json'\n",
    "y_vocab = '../data/hindi_map.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocab Sizes\n",
    "\n",
    "x: 1802939\n",
    "\n",
    "y: 2180936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 31018\n",
      "y: 27473\n"
     ]
    }
   ],
   "source": [
    "with open(x_vocab, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    total_vocab = len(data)\n",
    "    print(f'x: {total_vocab}')\n",
    "    \n",
    "with open(y_vocab, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    total_vocab = len(data)\n",
    "    print(f'y: {total_vocab}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loders(data_path, batch_size):\n",
    "    dataset = DatasetLanguage(data_path=data_path,\n",
    "                                x_vocab=x_vocab,\n",
    "                                y_vocab=y_vocab)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = get_loders(training_path, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_input = 31018\n",
    "vocab_size_output = 27473\n",
    "\n",
    "transformer_model = Transformer(\n",
    "    num_blocks=1,\n",
    "    d_model=512,\n",
    "    num_heads=8,\n",
    "    vocab_size_input=vocab_size_input,\n",
    "    vocab_size_output=vocab_size_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x0000012507F7BCA0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.001615  [    2/ 7000]\n",
      "loss: 0.001248  [  202/ 7000]\n",
      "loss: 0.001113  [  402/ 7000]\n",
      "loss: 0.002844  [  602/ 7000]\n",
      "loss: 0.001372  [  802/ 7000]\n",
      "loss: 0.000975  [ 1002/ 7000]\n",
      "loss: 0.010503  [ 1202/ 7000]\n",
      "loss: 0.001768  [ 1402/ 7000]\n",
      "loss: 0.001586  [ 1602/ 7000]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(transformer_model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "size = len(train_dataloader.dataset)\n",
    "batch_size = 2\n",
    "epochs = 2\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    transformer_model.train()\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        pred = transformer_model(X, y)\n",
    "        \n",
    "        y_one_hot = torch.nn.functional.one_hot(y, num_classes=vocab_size_output).to(torch.float)\n",
    "        loss = loss_fn(pred, y_one_hot)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.one_hot(y, num_classes=vocab_size_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.8621e-05, 2.7510e-05, 1.0490e-05,  ..., 2.6279e-05,\n",
       "          1.9552e-05, 6.6343e-05],\n",
       "         [1.6636e-05, 2.4985e-05, 1.7356e-05,  ..., 2.7062e-05,\n",
       "          1.9494e-05, 2.0020e-05],\n",
       "         [1.5191e-05, 4.7449e-05, 1.3954e-05,  ..., 2.3909e-05,\n",
       "          5.9029e-05, 3.1964e-05],\n",
       "         ...,\n",
       "         [2.4853e-05, 5.6504e-05, 1.0780e-05,  ..., 4.0894e-05,\n",
       "          3.7860e-05, 1.0435e-05],\n",
       "         [4.9898e-05, 5.6150e-05, 2.6220e-05,  ..., 7.2906e-05,\n",
       "          2.0828e-05, 3.4885e-05],\n",
       "         [3.1868e-05, 6.7873e-05, 1.5580e-05,  ..., 2.0059e-05,\n",
       "          5.1960e-05, 2.0337e-05]],\n",
       "\n",
       "        [[1.7727e-05, 2.8221e-05, 1.2633e-05,  ..., 2.9488e-05,\n",
       "          1.8888e-05, 6.6712e-05],\n",
       "         [3.6069e-05, 4.0887e-05, 3.1571e-05,  ..., 6.8090e-05,\n",
       "          3.2708e-05, 2.8404e-05],\n",
       "         [5.3294e-05, 2.8720e-05, 1.6916e-05,  ..., 3.4922e-05,\n",
       "          4.0616e-05, 3.6511e-05],\n",
       "         ...,\n",
       "         [2.2892e-05, 8.3273e-05, 1.1395e-05,  ..., 7.3501e-05,\n",
       "          2.6141e-05, 3.0824e-05],\n",
       "         [2.4166e-05, 8.2583e-05, 1.0660e-05,  ..., 7.2419e-05,\n",
       "          2.8678e-05, 3.0384e-05],\n",
       "         [2.7911e-05, 8.4769e-05, 9.7666e-06,  ..., 6.9655e-05,\n",
       "          3.1312e-05, 2.7904e-05]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
